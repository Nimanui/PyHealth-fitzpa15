{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimanui/PyHealth-fitzpa15/blob/SaliencyMappingGradient/ChestXrayClassificationWithSaliencyMapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Image Classification with PyHealth\n",
        "\n",
        "Welcome to the PyHealth tutorial on image classification. In this notebook, we will explore how to use PyHealth to analyze chest X-ray images and classify them into various chest diseases."
      ],
      "metadata": {
        "id": "I0KW-8CAZveh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "To begin, we need to install PyHealth and a few additional packages to support our analysis."
      ],
      "metadata": {
        "id": "m__yayCk5NRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne pandarallel rdkit transformers"
      ],
      "metadata": {
        "id": "MLep1QU2dW9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4A-aTU8Y0Od"
      },
      "outputs": [],
      "source": [
        "!rm -rf PyHealth-fitzpa15\n",
        "# !git clone https://github.com/sunlabuiuc/PyHealth.git\n",
        "!git clone -b SaliencyMappingGradient https://github.com/Nimanui/PyHealth-fitzpa15.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -e ./PyHealth-fitzpa15"
      ],
      "metadata": {
        "id": "Z3nSAoL5iha7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "sys.path.append(\"./pyHealth\")\n",
        "sys.path.append(\"./pyhealth-fitzpa15\")\n",
        "sys.path.append(\"./PyHealth\")\n",
        "sys.path.append(\"./Pyhealth-fitzpa15\")"
      ],
      "metadata": {
        "id": "eK9r5l1HZj62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data\n",
        "\n",
        "Next, we will download the dataset containing COVID-19 data. This dataset includes chest X-ray images of normal cases, lung opacity, viral pneumonia, and COVID-19 patients. You can find more information about the dataset [here](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database)."
      ],
      "metadata": {
        "id": "0rAm5xi_bpP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is hosted on Google Cloud, so the download speed should be relatively fast, taking approximately 10 seconds to complete."
      ],
      "metadata": {
        "id": "06WEJ4gN6Dsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://storage.googleapis.com/pyhealth/covid19_cxr_data/archive.zip"
      ],
      "metadata": {
        "id": "KUySVNhjZtc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o archive.zip"
      ],
      "metadata": {
        "id": "d7gG2oHVch2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 COVID-19_Radiography_Dataset"
      ],
      "metadata": {
        "id": "yRyJ7L3KdFy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will proceed with the chest X-ray classification task using PyHealth, following a five-stage pipeline."
      ],
      "metadata": {
        "id": "sLi4eI3K6Ov3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. Load Data in PyHealth\n",
        "\n",
        "The initial step involves loading the data into PyHealth's internal structure. This process is straightforward: import the appropriate dataset class from PyHealth and specify the root directory where the raw dataset is stored. PyHealth will handle the dataset processing automatically."
      ],
      "metadata": {
        "id": "kbtnYtJEbrkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.datasets import COVID19CXRDataset\n",
        "\n",
        "\n",
        "root = \"/content/COVID-19_Radiography_Dataset\"\n",
        "base_dataset = COVID19CXRDataset(root)"
      ],
      "metadata": {
        "id": "A31_DMb8bvMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data is loaded, we can perform simple queries on the dataset."
      ],
      "metadata": {
        "id": "2cE66-ET6zV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dataset.stats()"
      ],
      "metadata": {
        "id": "vOwzaQXOeEob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. Define the Task\n",
        "\n",
        "The next step is to define the machine learning task. This step instructs the package to generate a list of samples with the desired features and labels based on the data for each individual patient. Please note that in this dataset, patient identification information is not available. Therefore, we will assume that each chest X-ray belongs to a unique patient."
      ],
      "metadata": {
        "id": "RCihXswscAS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this dataset, PyHealth offers a default task specifically for chest X-ray classification. This task takes the image as input and aims to predict the chest diseases associated with it."
      ],
      "metadata": {
        "id": "aCE9DkGF7d54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dataset.default_task"
      ],
      "metadata": {
        "id": "wH7kxlONeJz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = base_dataset.set_task()"
      ],
      "metadata": {
        "id": "fPISD5BEb_k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example of a single sample, represented as a dictionary. The dictionary contains keys for feature names, label names, and other metadata associated with the sample."
      ],
      "metadata": {
        "id": "Z1qBa3bg8DgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset[0]"
      ],
      "metadata": {
        "id": "H6zlwzw5eZOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the input and output schemas, which specify the data types of the features and labels."
      ],
      "metadata": {
        "id": "KNC5CKNl8W75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset.input_schema"
      ],
      "metadata": {
        "id": "ClupS_1V8OVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset.output_schema"
      ],
      "metadata": {
        "id": "jb3yKtoi8RGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we plot the number of samples per classes, and visualize some samples."
      ],
      "metadata": {
        "id": "oTmlUXMI8cek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_dataset)"
      ],
      "metadata": {
        "id": "NPHQhGebzzDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = sample_dataset.output_processors[\"disease\"].label_vocab\n",
        "print(sample_dataset.output_schema)\n",
        "id2label = {v: k for k, v in label2id.items()}"
      ],
      "metadata": {
        "id": "6vx--7B6Ajgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "label_counts = defaultdict(int)\n",
        "for sample in sample_dataset.samples:\n",
        "    label_counts[id2label[sample[\"disease\"].item()]] += 1\n",
        "print(label_counts)\n",
        "plt.bar(label_counts.keys(), label_counts.values())"
      ],
      "metadata": {
        "id": "gfKvXzI0ebAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "label_to_idxs = defaultdict(list)\n",
        "for idx, sample in enumerate(sample_dataset.samples):\n",
        "    label_to_idxs[sample[\"disease\"].item()].append(idx)\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15, 3))\n",
        "for ax, label in zip(axs, label_to_idxs.keys()):\n",
        "    ax.set_title(id2label[label], fontsize=15)\n",
        "    idx = random.choice(label_to_idxs[label])\n",
        "    sample = sample_dataset[idx]\n",
        "    image = sample[\"image\"][0]\n",
        "    ax.imshow(image, cmap=\"gray\")"
      ],
      "metadata": {
        "id": "FRQy9yn0exXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will split the entire dataset into training, validation, and test sets using the ratios of 70%, 10%, and 20%, respectively. We will then obtain the corresponding data loaders for each set."
      ],
      "metadata": {
        "id": "aloIUVx78skB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.datasets import split_by_sample\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = split_by_sample(\n",
        "    dataset=sample_dataset,\n",
        "    ratios=[0.7, 0.1, 0.2]\n",
        ")"
      ],
      "metadata": {
        "id": "Z7oy63_1fGV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.datasets import get_dataloader\n",
        "\n",
        "\n",
        "train_dataloader = get_dataloader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = get_dataloader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_dataloader = get_dataloader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "dbK7hQKdf5Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. Define the Model\n",
        "\n",
        "Next, we will define the deep learning model we want to use for our task. PyHealth supports all major vision models available in the Torchvision package. You can load any of these models using the model_name argument."
      ],
      "metadata": {
        "id": "bjyBW4dQgO7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.models import TorchvisionModel\n",
        "\n",
        "\n",
        "resnet = TorchvisionModel(\n",
        "    dataset=sample_dataset,\n",
        "    model_name=\"resnet18\",\n",
        "    model_config={\"weights\": \"DEFAULT\"}\n",
        ")\n",
        "\n",
        "resnet"
      ],
      "metadata": {
        "id": "3Z2J5CodAWaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.models import TorchvisionModel\n",
        "\n",
        "\n",
        "vit = TorchvisionModel(\n",
        "    dataset=sample_dataset,\n",
        "    model_name=\"vit_b_16\",\n",
        "    model_config={\"weights\": \"DEFAULT\"}\n",
        ")\n",
        "\n",
        "vit"
      ],
      "metadata": {
        "id": "5vdHYugKgBSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 4. Training\n",
        "\n",
        "\n",
        "In this step, we will train the model using PyHealth's Trainer class, which simplifies the training process and provides standard functionalities."
      ],
      "metadata": {
        "id": "6oaLGeHRhdNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us first train the ResNet model."
      ],
      "metadata": {
        "id": "h_4bhS2XEK5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.trainer import Trainer\n",
        "\n",
        "\n",
        "resnet_trainer = Trainer(model=resnet)"
      ],
      "metadata": {
        "id": "ZdkL7AXchai8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we begin training, let's first evaluate the initial performance of the model."
      ],
      "metadata": {
        "id": "fwiGdYSoDiqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resnet_trainer.evaluate(test_dataloader))"
      ],
      "metadata": {
        "id": "KuD-_3c9hje8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's start the training process. Due to computational constraints, we will train the model for only one epoch."
      ],
      "metadata": {
        "id": "wugj9oGODnn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_trainer.train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    epochs=1,\n",
        "    monitor=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "id": "8EwqojOshov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the model, we can compare its performance before and after. We should expect to see an increase in the accuracy score as the model learns from the training data."
      ],
      "metadata": {
        "id": "9g9gWzq7D1u4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5. Evaluation\n",
        "\n",
        "Lastly, we can eavluate the ResNet model on the test set. This can be done using PyHealth's `Trainer.evaluate()` function."
      ],
      "metadata": {
        "id": "stYx6glgieDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resnet_trainer.evaluate(test_dataloader))"
      ],
      "metadata": {
        "id": "dAXux2AQiYVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, you can perform inference using the `Trainer.inference()` function."
      ],
      "metadata": {
        "id": "KA5308b1ET7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_prob, loss = resnet_trainer.inference(test_dataloader)\n",
        "y_pred = y_prob.argmax(axis=1)"
      ],
      "metadata": {
        "id": "v_ReFzoqiiow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we show a confusion matrix of the trained ResNet model."
      ],
      "metadata": {
        "id": "SPHJb7FgEfSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "ax = sns.heatmap(cf_matrix, linewidths=1, annot=True, fmt='g')\n",
        "ax.set_xticklabels([id2label[i] for i in range(4)])\n",
        "ax.set_yticklabels([id2label[i] for i in range(4)])\n",
        "ax.set_xlabel(\"Pred\")\n",
        "ax.set_ylabel(\"True\")"
      ],
      "metadata": {
        "id": "jOyaFNwzi3mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Gradient Saliency Mapping\n",
        "For a bonus let's look at some simple gradient saliency maps applied to our sample dataset."
      ],
      "metadata": {
        "id": "5RVEz8ZXX3ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_requires_grad(in_dataset):\n",
        "  for sample in in_dataset:\n",
        "    sample['image'].requires_grad_()"
      ],
      "metadata": {
        "id": "dos8kNYfX9eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.datasets import get_dataloader\n",
        "from pyhealth.interpret.methods.saliency import GradientSaliencyMapping\n",
        "batch_size = 32\n",
        "\n",
        "sample_dataloader = get_dataloader(sample_dataset.samples, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "saliency_maps = GradientSaliencyMapping(resnet, sample_dataloader, 20)"
      ],
      "metadata": {
        "id": "eS9S2NAPX_bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img, title):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def imshowSaliencyCompFromDict(saliency_dict_list, batch_index, image_index, title, alpha=0.3):\n",
        "    img = saliency_dict_list[batch_index]['image'][image_index]\n",
        "    saliency = saliency_dict_list[batch_index]['saliency'][image_index]\n",
        "    label = saliency_dict_list[batch_index]['label'][image_index]\n",
        "    new_title = str(title + \" \" + id2label[label.item()])\n",
        "    imshowSaliencyComp(img, saliency, new_title, alpha)\n",
        "\n",
        "def imshowSaliencyComp(img, saliency, title, alpha=0.3):\n",
        "    npimg = img.detach().numpy()\n",
        "    npimg = np.transpose(npimg, (1, 2, 0))\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(npimg.squeeze(), cmap='gray')\n",
        "    plt.imshow(saliency, cmap='hot', alpha=alpha)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BsJlC-ACYA9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_count = int(len(saliency_maps[0])/3)\n",
        "batch_size = len(saliency_maps[0]['saliency'])\n",
        "batch_random = random.randint(0, batch_count - 1)\n",
        "image_index_random = random.randint(0, batch_size - 1)\n",
        "imshowSaliencyCompFromDict(saliency_maps, batch_random, image_index_random, \"Gradient Saliency\", .6)"
      ],
      "metadata": {
        "id": "PHyxSrO8YDW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}